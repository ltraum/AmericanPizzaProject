{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8afe33",
   "metadata": {},
   "source": [
    "Lloom workbench created to connect with Streamlit app via Voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce173321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a13fa0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has OPENAI_API_KEY: True\n"
     ]
    }
   ],
   "source": [
    "# Imports & configuration\n",
    "import os, asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import ipywidgets as W  # Voilà-friendly widgets\n",
    "import text_lloom.workbench as wb\n",
    "\n",
    "# If you keep your key in .env, uncomment:\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path.cwd() / \"private\" / \".env\")\n",
    "\n",
    "# Make sure OPENAI_API_KEY is set in the environment your Voilà server uses.\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "print(\"Has OPENAI_API_KEY:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "DATA_PATH = \"/Users/ltraum/Documents/GitHub/AmericanPizzaProject/data/pizza_interviews.xlsx\"\n",
    "\n",
    "DEMO_COLS = [\n",
    "    \"participant_id\",\"age\",\"city_of_residence\",\"state_of_residence\",\n",
    "    \"region_of_residence\",\"income\",\"pizza_consumption\",\"food_restrictions\",\n",
    "]\n",
    "RESPONSE_COLS = [\"q1_response\",\"q2_response\",\"q3_response\",\"q4_response\",\"q5_response\"]\n",
    "\n",
    "# Load once (fast enough)\n",
    "df_full= pd.read_excel(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e471b0",
   "metadata": {},
   "source": [
    "import os, asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ipywidgets as W\n",
    "import text_lloom.workbench as wb\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "RESPONSE_COLS = [\"q1_response\",\"q2_response\",\"q3_response\",\"q4_response\",\"q5_response\"]\n",
    "regions = sorted([r for r in df_full[\"region_of_residence\"].dropna().unique()])\n",
    "\n",
    "# --- Widgets ---\n",
    "w_regions = W.SelectMultiple(options=regions, description=\"Regions\", rows=5, layout=W.Layout(width=\"45%\"))\n",
    "w_qs      = W.SelectMultiple(options=RESPONSE_COLS, value=(\"q1_response\",), description=\"Questions\", rows=5, layout=W.Layout(width=\"45%\"))\n",
    "w_seed    = W.Text(value=\"\", description=\"Seed\", placeholder=\"optional\", layout=W.Layout(width=\"45%\"))\n",
    "w_max     = W.IntSlider(value=3, min=1, max=10, step=1, description=\"Max themes\", layout=W.Layout(width=\"45%\"))\n",
    "w_run     = W.Button(description=\"Run LLooM\", button_style=\"primary\", layout=W.Layout(width=\"220px\"))\n",
    "w_status  = W.HTML(value=\"\")\n",
    "\n",
    "# Output areas\n",
    "out_summary   = W.Output()\n",
    "out_workbench = W.Output()\n",
    "\n",
    "ui = W.VBox([\n",
    "    W.HTML(\"<h3>LLooM Workbench — American Pizza Project</h3>\"),\n",
    "    W.HTML(\"<p>Select a seed & which questions to include (Q1 vs Q1+Q2…); then click <b>Run LLooM</b>.</p>\"),\n",
    "    W.HBox([w_regions, w_qs]),\n",
    "    W.HBox([w_seed, w_max]),\n",
    "    w_run,\n",
    "    w_status,\n",
    "    W.HTML(\"<hr><h4>LLooM Workbench (native viz)</h4>\"),\n",
    "    out_workbench\n",
    "])\n",
    "display(ui)\n",
    "\n",
    "def _build_text_df(df, questions):\n",
    "    text = df[list(questions)].apply(\n",
    "        lambda row: \" \".join([str(r) for r in row if pd.notnull(r) and str(r).strip()!=\"\"]).strip(),\n",
    "        axis=1\n",
    "    )\n",
    "    out = df.copy()\n",
    "    out[\"text\"] = text\n",
    "    out = out[out[\"text\"]!=\"\"].copy()\n",
    "    out[\"doc_id\"] = out.get(\"participant_id\", out.index).astype(str)\n",
    "    return out\n",
    "\n",
    "async def _run():\n",
    "    try:\n",
    "        w_status.value = \"<span style='color:gray'>Preparing data…</span>\"\n",
    "\n",
    "        # Slice & text build\n",
    "        regs = list(w_regions.value) if len(w_regions.value) else None\n",
    "        df_slice = df_full if not regs else df_full[df_full[\"region_of_residence\"].isin(regs)].copy()\n",
    "        df_run = _build_text_df(df_slice, list(w_qs.value))\n",
    "\n",
    "        if df_run.empty:\n",
    "            w_status.value = \"<span style='color:#b00'>No text rows after filters/questions.</span>\"\n",
    "            with out_workbench: clear_output()\n",
    "            return\n",
    "\n",
    "        # LLooM\n",
    "        w_status.value = \"<span style='color:gray'>Running LLooM…</span>\"\n",
    "        l = wb.lloom(df=df_run, text_col=\"text\", id_col=\"doc_id\")\n",
    "        await l.gen_auto(max_concepts=int(w_max.value), seed=(w_seed.value or None), debug=False)\n",
    "\n",
    "        # Render native LLooM matrix (with region slice)\n",
    "        with out_workbench:\n",
    "            clear_output()\n",
    "            l.vis(slice_col=\"region_of_residence\")\n",
    "\n",
    "        w_status.value = \"<span style='color:green'>Done.</span>\"\n",
    "\n",
    "    except Exception as e:\n",
    "        w_status.value = f\"<span style='color:#b00'>Error: {e}</span>\"\n",
    "\n",
    "def _on_click(_):\n",
    "    asyncio.create_task(_run())\n",
    "\n",
    "w_run.on_click(_on_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f01389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mEstimated cost\u001b[0m: $0.12\n",
      "**Please note that this is only an approximate cost estimate**\n",
      "\n",
      "\n",
      "\u001b[48;5;117mDistill-filter\u001b[0m\n",
      "✅ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mDistill-summarize\u001b[0m\n",
      "✅ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mCluster\u001b[0m\n",
      "✅ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mSynthesize\u001b[0m\n",
      "⠹ Loading "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltraum/Documents/GitHub/AmericanPizzaProject/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ltraum/Documents/GitHub/AmericanPizzaProject/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done    \n",
      "✅ Done with concept generation!\n",
      "\n",
      "\n",
      "\u001b[1mActive concepts\u001b[0m (n=5):\n",
      "- \u001b[1mRegional Pizza Preferences\u001b[0m: Does the text describe specific regional pizza styles or preferences?\n",
      "- \u001b[1mPizza as Social Food\u001b[0m: Does the text highlight pizza as a social or family-oriented food?\n",
      "- \u001b[1mIngredient and Quality Focus\u001b[0m: Does the text emphasize the importance of high-quality ingredients or specific pizza characteristics?\n",
      "- \u001b[1mPizza Evolution and Adaptation\u001b[0m: Does the text discuss changes in pizza preferences or adaptations over time?\n",
      "- \u001b[1mPizza as Convenience Food\u001b[0m: Does the text describe pizza as a convenient or practical food choice?\n",
      "\n",
      "\n",
      "Scoring 5 concepts for 50 documents\n",
      "\u001b[1mEstimated cost\u001b[0m: $0.02\n",
      "**Please note that this is only an approximate cost estimate**\n",
      "100%|██████████| 5/5 [00:44<00:00,  8.86s/it]\n",
      "✅ Done with concept scoring!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae75b30d7754f0eacaf75b64543f1bb",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "MatrixWidget(data='[{\"id\":\"All\",\"value\":39,\"example\":\"All\",\"_my_score\":0,\"concept\":\"Regional Pizza Preferences…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUESTIONS = [\"q1_response\", \"q2_response\", \"q3_response\", \"q4_response\", \"q5_response\"]\n",
    "# If you want a smaller scope, e.g. just Q4:\n",
    "# QUESTIONS = [\"q4_response\"]\n",
    "\n",
    "# 3) Build a text column by concatenating selected questions (skips blanks)\n",
    "text = df[QUESTIONS].apply(\n",
    "    lambda row: \" \".join([str(r) for r in row if pd.notnull(r) and str(r).strip() != \"\"]).strip(),\n",
    "    axis=1\n",
    ")\n",
    "df_run = df.copy()\n",
    "df_run[\"text\"] = text\n",
    "df_run = df_run[df_run[\"text\"] != \"\"].copy()\n",
    "\n",
    "# 4) Stable ID for LLooM\n",
    "#    Use participant_id if present; otherwise fall back to index\n",
    "if \"participant_id\" in df_run.columns:\n",
    "    df_run[\"doc_id\"] = df_run[\"participant_id\"].astype(str)\n",
    "else:\n",
    "    df_run[\"doc_id\"] = df_run.index.astype(str)\n",
    "\n",
    "# 5) Create LLooM instance and generate concepts (auto)\n",
    "l = wb.lloom(df=df_run, text_col=\"text\", id_col=\"doc_id\")\n",
    "score_df = await l.gen_auto(max_concepts=5, seed=None, debug=False)  # set seed=\"family\" etc. if you want\n",
    "\n",
    "# 6) Show the original LLooM Workbench UI (matrix).\n",
    "#    Add a slice by region like in the docs:\n",
    "l.vis(slice_col=\"region_of_residence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d92a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>criteria</th>\n",
       "      <th>summary</th>\n",
       "      <th>rep_examples</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>n_matches</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ingredient and Quality Focus</td>\n",
       "      <td>Does the text emphasize the importance of high...</td>\n",
       "      <td>We prioritize high-quality, fresh ingredients ...</td>\n",
       "      <td>[My big pizza moment was trying Regina's in th...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>43</td>\n",
       "      <td>[I love San Diego's fresh, California-style ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pizza Evolution and Adaptation</td>\n",
       "      <td>Does the text discuss changes in pizza prefere...</td>\n",
       "      <td>My pizza journey reflects regional influences,...</td>\n",
       "      <td>[My relationship with pizza has gone through p...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>39</td>\n",
       "      <td>[Pizza's just not something that was part of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza as Convenience Food</td>\n",
       "      <td>Does the text describe pizza as a convenient o...</td>\n",
       "      <td>Pizza is our go-to convenience food for casual...</td>\n",
       "      <td>[I've liked pizza since I was a kid and my pre...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>36</td>\n",
       "      <td>[Pizza is social food for me - splitting pies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pizza as Social Food</td>\n",
       "      <td>Does the text highlight pizza as a social or f...</td>\n",
       "      <td>Pizza is our go-to social food, perfect for ga...</td>\n",
       "      <td>[Detroit pizza isn't just food, it's cultural ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>44</td>\n",
       "      <td>[It's still social food for me, but I have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regional Pizza Preferences</td>\n",
       "      <td>Does the text describe specific regional pizza...</td>\n",
       "      <td>Regional pizza preferences reflect diverse sty...</td>\n",
       "      <td>[Moving to Boise from Chicago was a pizza cult...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>39</td>\n",
       "      <td>[New Mexico style with green chile is my go-to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          concept  \\\n",
       "0    Ingredient and Quality Focus   \n",
       "1  Pizza Evolution and Adaptation   \n",
       "2       Pizza as Convenience Food   \n",
       "3            Pizza as Social Food   \n",
       "4      Regional Pizza Preferences   \n",
       "\n",
       "                                            criteria  \\\n",
       "0  Does the text emphasize the importance of high...   \n",
       "1  Does the text discuss changes in pizza prefere...   \n",
       "2  Does the text describe pizza as a convenient o...   \n",
       "3  Does the text highlight pizza as a social or f...   \n",
       "4  Does the text describe specific regional pizza...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  We prioritize high-quality, fresh ingredients ...   \n",
       "1  My pizza journey reflects regional influences,...   \n",
       "2  Pizza is our go-to convenience food for casual...   \n",
       "3  Pizza is our go-to social food, perfect for ga...   \n",
       "4  Regional pizza preferences reflect diverse sty...   \n",
       "\n",
       "                                        rep_examples  prevalence  n_matches  \\\n",
       "0  [My big pizza moment was trying Regina's in th...        0.86         43   \n",
       "1  [My relationship with pizza has gone through p...        0.78         39   \n",
       "2  [I've liked pizza since I was a kid and my pre...        0.72         36   \n",
       "3  [Detroit pizza isn't just food, it's cultural ...        0.88         44   \n",
       "4  [Moving to Boise from Chicago was a pizza cult...        0.78         39   \n",
       "\n",
       "                                          highlights  \n",
       "0  [I love San Diego's fresh, California-style ap...  \n",
       "1  [Pizza's just not something that was part of m...  \n",
       "2  [Pizza is social food for me - splitting pies ...  \n",
       "3  [It's still social food for me, but I have to ...  \n",
       "4  [New Mexico style with green chile is my go-to...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    export_df = l.export_df()\n",
    "    display(export_df.head(10))\n",
    "except Exception as e:\n",
    "    print(\"export_df not available here:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc18e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_demographics(df, regions=None):\n",
    "    dff = df.copy()\n",
    "    if regions:\n",
    "        dff = dff[dff[\"region_of_residence\"].isin(regions)]\n",
    "    return dff.reset_index(drop=True)\n",
    "\n",
    "def build_text_df(df, questions):\n",
    "    if not questions:\n",
    "        raise ValueError(\"Pick at least one question column.\")\n",
    "    missing = [q for q in questions if q not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    text = (\n",
    "        df[questions]\n",
    "        .apply(lambda row: \" \".join([str(r) for r in row if pd.notnull(r) and str(r).strip() != \"\"]).strip(), axis=1)\n",
    "    )\n",
    "    out = df[DEMO_COLS].copy()\n",
    "    out[\"text\"] = text\n",
    "    out = out[out[\"text\"] != \"\"].copy()\n",
    "    out[\"doc_id\"] = out[\"participant_id\"].astype(str)\n",
    "    return out\n",
    "\n",
    "def build_export_from_long(score_df, concepts, threshold=0.75, doc_id_col=\"doc_id\"):\n",
    "    n_docs = score_df[doc_id_col].astype(str).nunique()\n",
    "    rows = []\n",
    "    for cid, meta in concepts.items():\n",
    "        name = meta.get(\"name\") or meta.get(\"concept\") or str(cid)\n",
    "        prompt = meta.get(\"prompt\") or \"\"\n",
    "        summary = meta.get(\"summary\")\n",
    "\n",
    "        sub = score_df[score_df[\"concept_id\"] == cid].copy()\n",
    "        sub[\"is_match\"] = pd.to_numeric(sub[\"score\"], errors=\"coerce\") >= threshold\n",
    "\n",
    "        n_matches = sub.loc[sub[\"is_match\"], doc_id_col].astype(str).nunique()\n",
    "        prevalence = (n_matches / n_docs) if n_docs else 0.0\n",
    "        highlights = (\n",
    "            sub.loc[sub[\"is_match\"], \"highlight\"]\n",
    "               .dropna()\n",
    "               .astype(str)\n",
    "               .head(3)\n",
    "               .tolist()\n",
    "        )\n",
    "        rows.append({\n",
    "            \"concept\": name,\n",
    "            \"criteria\": prompt,\n",
    "            \"summary\": summary,\n",
    "            \"prevalence\": prevalence,\n",
    "            \"n_matches\": int(n_matches),\n",
    "            \"highlights\": highlights,\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"n_matches\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6714ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a421de0f7b48fc8244ede266d422a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>LLooM Workbench (American Pizza Project)</h3>'), HTML(value='<p>Select filters …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widget controls\n",
    "regions = sorted([r for r in df_full[\"region_of_residence\"].dropna().unique()])\n",
    "w_regions = W.SelectMultiple(options=regions, description=\"Regions\", rows=6, layout=W.Layout(width=\"45%\"))\n",
    "\n",
    "w_qs = W.SelectMultiple(\n",
    "    options=RESPONSE_COLS,\n",
    "    value=(\"q1_response\",),\n",
    "    description=\"Questions\",\n",
    "    rows=6,\n",
    "    layout=W.Layout(width=\"45%\")\n",
    ")\n",
    "\n",
    "w_seed = W.Text(value=\"\", description=\"Seed\", placeholder=\"optional\", layout=W.Layout(width=\"45%\"))\n",
    "w_max = W.IntSlider(value=5, min=1, max=10, step=1, description=\"Max themes\", layout=W.Layout(width=\"45%\"))\n",
    "w_thresh = W.FloatSlider(value=0.75, min=0.5, max=0.95, step=0.05, description=\"Threshold\", readout_format=\".2f\", layout=W.Layout(width=\"45%\"))\n",
    "\n",
    "w_run = W.Button(description=\"Run LLooM\", button_style=\"primary\", layout=W.Layout(width=\"200px\"))\n",
    "w_status = W.HTML(value=\"\")\n",
    "\n",
    "# Output areas\n",
    "out_summary = W.Output()\n",
    "out_workbench = W.Output()\n",
    "\n",
    "ui = W.VBox([\n",
    "    W.HTML(\"<h3>LLooM Workbench (American Pizza Project)</h3>\"),\n",
    "    W.HTML(\"<p>Select filters and parameters, then click <b>Run LLooM</b>.</p>\"),\n",
    "    W.HBox([w_regions, w_qs]),\n",
    "    W.HBox([w_seed, w_max]),\n",
    "    W.HBox([w_thresh, w_run]),\n",
    "    w_status,\n",
    "    W.HTML(\"<hr><h4>Themes Summary</h4>\"),\n",
    "    out_summary,\n",
    "    W.HTML(\"<hr><h4>LLooM Workbench</h4>\"),\n",
    "    W.HTML(\"<p>Interactive matrix view of concepts × slices (slice: <code>region_of_residence</code>).</p>\"),\n",
    "    out_workbench,\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c4ba397",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_lloom_once():\n",
    "    try:\n",
    "        w_status.value = \"<span style='color:gray'>Preparing data…</span>\"\n",
    "\n",
    "        # Slice & build\n",
    "        regs = list(w_regions.value) if len(w_regions.value) else None\n",
    "        df_slice = filter_demographics(df_full, regions=regs)\n",
    "        df_text = build_text_df(df_slice, list(w_qs.value))\n",
    "\n",
    "        if df_text.empty:\n",
    "            w_status.value = \"<span style='color:#b00'>No text rows after filters/questions.</span>\"\n",
    "            with out_summary: \n",
    "                clear_output()\n",
    "                display(pd.DataFrame(columns=[\"concept\",\"prevalence\",\"n_matches\",\"highlights\"]))\n",
    "            with out_workbench:\n",
    "                clear_output()\n",
    "            return\n",
    "\n",
    "        # LLooM\n",
    "        w_status.value = \"<span style='color:gray'>Running LLooM induction…</span>\"\n",
    "        l = wb.lloom(df=df_text, text_col=\"text\", id_col=\"doc_id\")\n",
    "        score_df = await l.gen_auto(max_concepts=int(w_max.value), seed=(w_seed.value or None), debug=False)\n",
    "        concepts = {cid: c.to_dict() for cid, c in l.concepts.items()}\n",
    "\n",
    "        # Summary\n",
    "        w_status.value = \"<span style='color:gray'>Building summary…</span>\"\n",
    "        export_df = build_export_from_long(score_df, concepts, threshold=float(w_thresh.value))\n",
    "\n",
    "        # Show summary\n",
    "        with out_summary:\n",
    "            clear_output()\n",
    "            if export_df.empty:\n",
    "                display(pd.DataFrame(columns=[\"concept\",\"prevalence\",\"n_matches\",\"highlights\"]))\n",
    "            else:\n",
    "                # Show only non-zero matches; cap to top N=max_concepts\n",
    "                shown = export_df[export_df[\"n_matches\"] > 0].head(int(w_max.value)).copy()\n",
    "                shown[\"prevalence (%)]\"] = (shown[\"prevalence\"] * 100).round(1)\n",
    "                display(shown[[\"concept\",\"prevalence (%)]\",\"n_matches\",\"highlights\"]])\n",
    "\n",
    "        # Show native LLooM visual (matrix)\n",
    "        w_status.value = \"<span style='color:gray'>Rendering Workbench…</span>\"\n",
    "        with out_workbench:\n",
    "            clear_output()\n",
    "            l.vis(slice_col=\"region_of_residence\")  # native LLooM UI\n",
    "\n",
    "        w_status.value = \"<span style='color:green'>Done.</span>\"\n",
    "\n",
    "    except Exception as e:\n",
    "        w_status.value = f\"<span style='color:#b00'>Error: {e}</span>\"\n",
    "\n",
    "def on_click_run(_btn):\n",
    "    # schedule the coroutine without blocking the UI (Voilà/Jupyter)\n",
    "    asyncio.create_task(run_lloom_once())\n",
    "\n",
    "w_run.on_click(on_click_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863b8c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mEstimated cost\u001b[0m: $0.06\n",
      "**Please note that this is only an approximate cost estimate**\n",
      "\n",
      "\n",
      "\u001b[48;5;117mDistill-filter\u001b[0m\n",
      "✅ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mDistill-summarize\u001b[0m\n",
      "✅ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mCluster\u001b[0m\n",
      "✅ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mSynthesize\u001b[0m\n",
      "⠹ Loading "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltraum/Documents/GitHub/AmericanPizzaProject/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ltraum/Documents/GitHub/AmericanPizzaProject/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done    \n",
      "✅ Done with concept generation!\n",
      "\n",
      "\n",
      "\u001b[1mActive concepts\u001b[0m (n=5):\n",
      "- \u001b[1mUnique Toppings\u001b[0m: Does the text example mention unique or unconventional pizza toppings?\n",
      "- \u001b[1mEvolving Pizza Trends\u001b[0m: Does the text example highlight changes or trends in pizza styles or preferences over time?\n",
      "- \u001b[1mPizza as Craft\u001b[0m: Does the text example appreciate pizza as a craft or art form?\n",
      "- \u001b[1mLocal Ingredients\u001b[0m: Does the text emphasize the use of local ingredients in pizza making?\n",
      "- \u001b[1mCultural Identity\u001b[0m: Does the text discuss how pizza represents or reflects cultural identity?\n",
      "\n",
      "\n",
      "Scoring 5 concepts for 50 documents\n",
      "\u001b[1mEstimated cost\u001b[0m: $0.02\n",
      "**Please note that this is only an approximate cost estimate**\n",
      "100%|██████████| 5/5 [00:44<00:00,  8.92s/it]\n",
      "✅ Done with concept scoring!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba001006f514030b658227c95682ee5",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "MatrixWidget(data='[{\"id\":\"All\",\"value\":17,\"example\":\"All\",\"_my_score\":0,\"concept\":\"Unique Toppings\",\"n\":17},{…"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "import text_lloom.workbench as wb\n",
    "\n",
    "# 1) Confirm key\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not set. Export it or load from .env\"\n",
    "\n",
    "# 2) Build a tiny df_text (doc_id + text + region)\n",
    "df1 = df[[\"participant_id\",\"region_of_residence\",\"q1_response\"]].copy()\n",
    "df1 = df1.rename(columns={\"q1_response\":\"text\"})\n",
    "df1 = df1[df1[\"text\"].notna() & (df1[\"text\"].str.strip()!=\"\")]\n",
    "df1[\"doc_id\"] = df1[\"participant_id\"].astype(str)\n",
    "df_text = df1[[\"doc_id\",\"text\",\"region_of_residence\"]].head(50)  # small slice\n",
    "\n",
    "# 3) Run LLooM + show workbench\n",
    "l = wb.lloom(df=df_text, text_col=\"text\", id_col=\"doc_id\")\n",
    "await l.gen_auto(max_concepts=5, seed=None, debug=False)\n",
    "\n",
    "# IMPORTANT: end the cell with the widget so it renders\n",
    "l.vis(slice_col=\"region_of_residence\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
